{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from move_chess.environment import Board\n",
    "from move_chess.agent import Piece\n",
    "from move_chess.learn import Reinforce\n",
    "\n",
    "env = Board()\n",
    "p = Piece(piece='rook')\n",
    "r = Reinforce(p,env)\n",
    "\n",
    "r.policy_iteration(k=1,gamma=1,synchronous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from move_chess.environment import Board\n",
    "from move_chess.agent import Piece\n",
    "from move_chess.learn import Reinforce\n",
    "\n",
    "p = Piece(piece='king')\n",
    "env = Board()\n",
    "r = Reinforce(p,env)\n",
    "r.q_learning(n_episodes=1000,alpha=0.2,gamma=0.9)\n",
    "r.visualize_policy()\n",
    "r.agent.action_function.max(axis=2).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "board = chess.Board()\n",
    "from capture_chess.environment import Board\n",
    "from capture_chess.learn import Reinforce\n",
    "from capture_chess.agent import Agent\n",
    "\n",
    "board = Board()\n",
    "agent = Agent(network='conv_pg',lr=0.3)\n",
    "R = Reinforce(agent,board)\n",
    "pgn = R.learn(iters=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from real_chess import agent, environment, learn, tree\n",
    "import chess\n",
    "from chess.pgn import Game\n",
    "\n",
    "\n",
    "opponent = agent.GreedyAgent()\n",
    "env = environment.Board(opponent, FEN=None)\n",
    "player = agent.Agent(lr=0.5,network='super_simple')\n",
    "learner = learn.TD_search(env, player,gamma=0.9,search_time=0.9)\n",
    "node = tree.Node(learner.env.board, gamma=learner.gamma)\n",
    "player.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1  # maximum number of iterations\n",
    "timelimit = 1# maximum time for learning\n",
    "network_replacement_interval = 1  # For the stability of the nearal network updates, the network is not continuously replaced\n",
    "learner.learn(iters=n_iters,timelimit_seconds=timelimit,c=network_replacement_interval) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
